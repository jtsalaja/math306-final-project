---
title: "Predicting Startup Exit Outcomes Using Least Squares Classification"
author: "Noah Jarbeau, Phattiya Matrakul, Jelizaveta Tsalaja"
date: "`r Sys.Date()`"
output: github_document
---

```{r include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(caret)
library(ggplot2)

startups <- read.csv("/cloud/project/startup_data.csv")

colnames(startups) <- c("startup_name", "industry", "funding_rounds", "funding_amount", "valuation", "revenue", "employees", "market_share_percent", "profitable", "year_founded", "region", "exit_status")
head(startups)


```

## Introduction

Startups operate in high-stakes, fast-moving environments where financial outcomes often hinge on a mix of strategic, operational, and external factors. In these markets, understanding what influences a startup’s ability to secure funding and ultimately achieve a successful exit—whether through acquisition, an IPO, or remaining private—can be critical for founders and investors. This project explores which financial and operational factors are most strongly linked to startup success by applying linear algebra concepts, particularly Least Squares Classification (LSC), to a real-world dataset. Our main research question is: which variables best predict whether a startup will get acquired, go public, or remain private? This question is not only statistically interesting, but also practically useful in helping stakeholders allocate resources and make strategic decisions based on meaningful, data-driven patterns. By understanding these patterns, founders and investors can focus on the metrics that truly matter. 


## Motivation and Background

With access to funding data and financial reports, we can approach startup performance prediction through quantitative modeling. Our analysis uses the Startup Growth & Funding dataset [1]. It contains a sample of 500 startups across multiple industries, relating to financial, operational, and market-related characteristics. We will analyze 11 variables by mixing numerical and categorical features that contribute to an understanding of startup performance.

The numerical variables include funding rounds, funding amount (in millions of USD), valuation (in millions of USD), revenue (in millions of USD), number of employees, market share percentage, and the year the startup was founded. Funding rounds tell us how many rounds a company goes through in seeking funds. In each stage, companies seek funding capital from investors, which is intended to help grow the company.  In general, a higher number of rounds means there are more investors.  Valuation is a current or projected worth of the company [2]. It may take into consideration market trends and competition. Revenue is the amount of money the company earns before expenses are deducted. Market share is “the percent of total sales in an industry generated by a particular company” [3].

Categorical variables include industry (e.g., AI, FinTech, HealthTech), profitability (binary indicator: profitable or not), exit status (IPO, acquired, or private), and region (e.g., Europe, South America, North America). 
Taken together, these features capture both the financial underpinnings of a startup (e.g., how much funding it has raised and its overall valuation) and its operational environment (e.g., market share and region). By applying LSC to these variables, we can indicate which factors—like funding rounds or profitability—most strongly predict whether a startup remains private, launches an IPO, or gets acquired. In turn, founders and investors can focus their energy on what truly drives success, making data-informed decisions about fundraising strategy, growth plans, and long-term sustainability.

To understand the data better before modeling, we visualized some key relationships. The first visualization was a stacked bar chart showing exit status broken down by industry.


### Exit Status by Industry

```{r fig1, echo=FALSE, fig.cap="Figure 1: Exit Status by Indsutry"}
ggplot(startups, aes(x = industry, fill = exit_status)) +
  scale_fill_viridis_d(direction = -1, name = "Exit Status") +
  geom_bar(position = "fill", alpha = 0.7) +  # Stacked bar chart normalized to proportions
  labs(title = "Exit Status by Industry",
       x = "Industry",
       y = "Proportion of Exit Status") +
  theme_minimal() +
  coord_flip()

ggsave("visualisation1.jpeg")
```


The first visualization (Figure 1) shows the Exit Status by Industry as a stacked bar chart, where each industry is represented by the proportion of startups that were acquired, went public (IPO), or remained private. We noticed that industries like FinTech and HealthTech had a higher percentage of successful exits (either acquisition or IPO), while fields like Gaming and IoT had more startups that remained private. This breakdown highlights how industry sector plays a potentially important role in determining exit outcomes—suggesting that certain market sectors may offer more favorable conditions for scaling and investment returns. This observation motivated us to include “industry” as a key feature in our modeling.

The second visualization was a boxplot of funding amount against exit status.

### Funding Amount vs Exit Status

```{r fig2, echo=FALSE, fig.cap="Figure 2: Exit Status by Funding Amount"}
ggplot(startups, aes(x = exit_status, y = funding_amount, fill = exit_status)) +
  geom_boxplot(alpha = 0.8) +
  scale_fill_viridis_d(name = "Exit Status") +  # Updated legend title
  labs(
    title = "Funding Amount vs. Exit Status",
    x = "Exit Status",
    y = "Funding Amount"
  ) +
  theme_minimal()
ggsave("visualisation2.jpeg")
```


The second visualization (Figure 2) displays a boxplot of Funding Amount vs. Exit Status on a log scale. Surprisingly, the median funding amounts across the three categories (Acquired, IPO, Private) were quite similar, with only small differences in spread and range. This was unexpected—we originally thought funding would be one of the most important predictors of success. But the visualization showed us that funding alone doesn’t clearly separate the outcomes, and it might not be as strong a signal as we assumed. Instead, the plot reinforces the importance of considering other variables such as region in our classification model, as funding alone does not clearly separate the categories.

Together, these visualizations gave us important insight into the patterns within our dataset. They helped us narrow our focus on variables with stronger predictive signals and confirmed that some intuitive assumptions (such as higher funding directly leading to IPOs) don’t always hold when observed through real data.

## Methods Employed

In this project, we applied several linear algebra concepts to prepare our data and build a model that predicts a startup’s exit status. We began by loading a dataset containing information about startups and set a random seed to ensure reproducibility. Then, we cleaned the data by removing any missing values and renaming the columns for clarity. Since the startup name was non-numeric and not useful for modeling, we dropped it. Next, we converted categorical variables such as “exit_status,” “industry,” and “region” into numeric factors so they could be used in our model.

After preprocessing, we standardized the numeric features, which involved transforming each column so that it had a mean of 0 and standard deviation of 1. This step used ideas from vector norms and scalar multiplication, and helped make sure all features contributed equally. Without normalization, variables with larger numeric ranges could dominate the model. We then combined the scaled features with the exit status and split the data into training (80%) and testing (20%) sets. To prepare for modeling, we created dummy variables for the predictors.

To classify startups into one of three possible outcomes—acquired, IPO, or private—we used a multi-class least squares classification model. Specifically, we fit three separate linear models, one for each outcome. For each startup, we generated predictions from all three models, organized the results into a matrix, and then assigned each startup to the class with the highest predicted value. We evaluated the model’s performance using a confusion matrix, which compared the predicted classes to the actual exit statuses.

From a linear algebra perspective, the model learns a set of directions (or weight vectors) in space that best separate the outcomes. Each class has its own weight vector, and the model calculates a score for each class by taking the dot product between the startup’s feature vector and the class’s weight vector. The class with the highest score becomes the prediction. This process connects closely to our work on vector projections and orthonormal vectors to understand how one vector points in the direction of another. In this context, each startup is a point in high-dimensional space, and the model essentially projects that point onto the direction of each class to determine which it’s most aligned with. 



```{r model-training, message=FALSE, warning=FALSE, include=FALSE}
library(dplyr)
library(caret)

# Load data
startups_data <- read.csv("/cloud/project/startup_data.csv")

# Set seed for reproducibility
set.seed(41)

# Rename columns (do this *before* removing NAs so that names are correct)
colnames(startups_data) <- c("startup_name", "industry", "funding_rounds", "funding_amount", "valuation", "revenue", "employees", "market_share_percent", "profitable", "year_founded", "region", "exit_status")

# Remove missing values
startups_data <- na.omit(startups_data)

# Keep companies founded after 1990
startups_data <- startups_data %>%
  filter(year_founded > 1990)

# Drop 'startup_name' (non-numeric identifier)
startups_data <- startups_data %>%
  select(-startup_name)

# Convert categorical variables into numeric factors
startups_data$exit_status <- as.numeric(factor(startups_data$exit_status))
startups_data$industry <- as.numeric(factor(startups_data$industry))
startups_data$region <- as.numeric(factor(startups_data$region))

# Save the exit status separately for later
exit <- startups_data$exit_status

# Drop the exit_status column for scaling
startups_data_numeric <- startups_data %>%
  select(-exit_status)

# Scale numeric columns
startups_data_scaled <- scale(startups_data_numeric) %>%
  as.data.frame()

# Add the exit_status column back
startups_data_scaled_final <- cbind(startups_data_scaled, exit_status = exit)

# Split data: 90% train, 10% test
train_index <- createDataPartition(startups_data_scaled_final$exit_status, p = 0.9, list = FALSE)
train_data <- startups_data_scaled_final[train_index, ]
test_data  <- startups_data_scaled_final[-train_index, ]

# Least squares classification (1: Acquired, 2: IPO, 3: Private)
lm_acquired <- lm(I(exit_status == 1) ~ . - exit_status, data = train_data)
lm_ipo      <- lm(I(exit_status == 2) ~ . - exit_status, data = train_data)
lm_private  <- lm(I(exit_status == 3) ~ . - exit_status, data = train_data)

# Predict probabilities for each class
pred_acquired <- predict(lm_acquired, newdata = test_data)
pred_ipo      <- predict(lm_ipo, newdata = test_data)
pred_private  <- predict(lm_private, newdata = test_data)

# Combine predictions
pred_matrix <- cbind(pred_acquired, pred_ipo, pred_private)

# Adjust IPO predictions (if desired for boosting)
pred_matrix_adj <- pred_matrix
pred_matrix_adj[,2] <- pred_matrix_adj[,2] + 0.4  # Boost IPO class

# Classify to the class with max predicted value
pred_class <- max.col(pred_matrix_adj)

# Evaluate predictions
true_class <- factor(test_data$exit_status, levels = 1:3)
pred_class <- factor(pred_class, levels = 1:3)

# Confusion matrix
conf_matrix <- confusionMatrix(pred_class, true_class)
print(conf_matrix)

```


## Results

Our research question was: what features can help predict if a startup will be acquired, go public, or remain private? To answer this, we used the matrix of startup features we created, and applied a classification method similar to the multi-class classifier we studied in the class. The model looks at relationships between the features and the outcome by treating each startup as a point in high-dimensional space. It then uses linear projections and weight vectors to predict which class (exit status) each startup belongs to.

After evaluating the results, we found that region and industry were more helpful in predicting outcomes than we originally thought. When these variables were taken away, the accuracy of the model decreased.  

The model achieved an overall accuracy of 70.8%, matching the baseline “no information” rate of 70.8%, which assumes all startups are classified as the majority class (“Private”). However, this accuracy comes with significant caveats. The wide 95% confidence interval (55.9%–83.1%) reflects uncertainty due to the limited test dataset, and the moderate Kappa score of 0.041 suggests only partial agreement between predictions and true outcomes. Class-specific performance further underscored these limitations. The model perfectly identified “Private” startups (100% sensitivity) but completely failed to detect “Acquired” startups (0% sensitivity), likely due to the stark class imbalance: “Private” startups dominated the dataset (70.8% prevalence), while “Acquired” startups were rare (18.8% prevalence). For IPOs, the model achieved 0% sensitivity, failing to identify any true cases, but its high specificity (97.7%) meant IPO predictions were highly reliable when made. However, the sample size was rather small, and this high precision may in some ways be attributed to luck.


```{r echo=FALSE}
conf_matrix
```


```{r include=FALSE}
# Extract coefficients for each model
coef_acquired <- summary(lm_acquired)$coefficients
coef_ipo <- summary(lm_ipo)$coefficients
coef_private <- summary(lm_private)$coefficients

# Create a data frame of coefficients for each class
importance_df <- data.frame(
  Variable = rownames(coef_acquired),
  Acquired = coef_acquired[, "Estimate"],
  IPO = coef_ipo[, "Estimate"],
  Private = coef_private[, "Estimate"]
)

# Remove the intercept row (optional)
importance_df <- importance_df[-1, ]

# Rank variables by absolute coefficient value for each class
importance_df$Abs_Acquired <- abs(importance_df$Acquired)
importance_df$Abs_IPO <- abs(importance_df$IPO)
importance_df$Abs_Private <- abs(importance_df$Private)

# Sort by importance for each class
importance_acquired <- importance_df[order(-importance_df$Abs_Acquired), ]
importance_ipo <- importance_df[order(-importance_df$Abs_IPO), ]
importance_private <- importance_df[order(-importance_df$Abs_Private), ]

# Print top 5 variables for each class
cat("Top variables for Acquired:\n")
print(head(importance_acquired[, c("Variable", "Acquired")], 5))

cat("\nTop variables for IPO:\n")
print(head(importance_ipo[, c("Variable", "IPO")], 5))

cat("\nTop variables for Private:\n")
print(head(importance_private[, c("Variable", "Private")], 5))

library(tidyr)
library(ggplot2)

# Reshape data for plotting
plot_data <- importance_df %>%
  pivot_longer(
    cols = c(Acquired, IPO, Private),
    names_to = "Class",
    values_to = "Coefficient"
  )
```


Variable importance analysis revealed distinct patterns across exit types. Revenue emerged as a critical but context-dependent predictor. Higher revenue reduced the likelihood of acquisition (coefficient: −0.11), suggesting that startups with substantial revenue may prioritize independence or alternative exit strategies, while lower-revenue companies might attract acquirers seeking growth potential.


```{r echo=FALSE, fig.cap="Figure 3: Varibale Importance by Exit Status"}
# Plot coefficients
ggplot(plot_data, aes(x = reorder(Variable, abs(Coefficient)), y = Coefficient, fill = Class)) +
  geom_bar(stat = "identity", position = "dodge",alpha = 0.8) +
  coord_flip() +
  scale_fill_viridis_d() +
  labs(
    title = "Variable Importance by Exit Status",
    x = "Variable",
    y = "Coefficient (Impact)"
  ) +
  theme_minimal()
```

Conversely, revenue positively influenced IPO outcomes (coefficient: +0.04). This makes sense, because startups that are financially successful should be more likely to go public. Employees also played a pivotal role: larger teams strongly predicted a reduced likelihood of remaining private (coefficient: −0.87), possibly because scaling workforce size correlates with readiness for exit events. Region and industry, initially underestimated, proved vital. Their removal degraded model accuracy, and their coefficients—such as region’s negative impact on acquisitions (−0.05)—hinted at geographic or sector-specific trends in exit behavior. For instance, startups in certain regions might face fewer acquisition opportunities due to market fragmentation or investor preferences.

## Future Work

This project helped us apply many linear algebra topics we covered in class, including vector norms, matrix multiplication, and classification. We learned how to structure real-world data into a matrix by using linear combinations to make predictions and interpreting which directions in the data space were most important. 

During this project we learned how important the choice of data can be. We learned how to apply the coding we have learned to new tasks, and how there are many possibilities when it comes to applying the methods we have learned. For instance, we could have also switched to use the backup data we chose, which was on smartwatch data. This shows how once a model is built, it can be adapted for many different uses. 

Possible next steps would include finding a way to deal with data imbalance, and using regularization techniques to improve the accuracy of the model. We could also use dimensionality reduction techniques like eigendecomposition or PCA to understand the most important directions in the data. 

Overall, this project helped us connect mathematical modeling to a concrete business problem, deepening our understanding of both linear algebra and the startup ecosystem. While our model was only moderately successful at predicting outcomes, the process of building it—and seeing which features mattered most—provided valuable insights into how data-driven models can challenge assumptions, highlight unexpected patterns, and inform better decisions in real-world settings.


## References

[1]  Ashar, Samay. “Startup Growth & Funding Trends.” Kaggle.com, 2025. https://doi.org/10853721/aa2f631868a1247c4a97ae6fb7063149.

[2]Hayes, Adam. “Market Share: What It Is and the Formula for Calculating It.” Investopedia, 23 Aug. 2024, https://www.investopedia.com/terms/m/marketshare.asp.

[3] Chen, James. “How the Valuation Process Works.” Investopedia, 30 June 2023, https://www.investopedia.com/terms/v/valuation.asp.
